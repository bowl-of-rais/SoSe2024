----

#domains #datasets

----
# Domains and datasets

in general:
- mostly found question answering datasets
	- often less focused on reasoning
	- math datasets tend to show reasoning in solution, downside: latex
- domains found: math (4), biomedical (2), general STEM (2), logic/climate (1)
- if considering basic arithmatic: finance, some math
- maybe more niche but interesting: deception - dialogue format, find lies based on inconsistencies?
	- https://dl.acm.org/doi/abs/10.1145/3603163.3609057
	- https://link.springer.com/chapter/10.1007/978-3-031-47994-6_24
	- https://ieeexplore.ieee.org/abstract/document/9206937

# Math ðŸ”¢

| Advantages               | Disadvantages                                             |
| ------------------------ | --------------------------------------------------------- |
| we have domain knowledge | format often not purely text-based, but includes eg LaTeX |
##### General Ideas
- counterfactuals: generated by supplying fake axioms or sth? then classify correct or not?

### 1. MATH dataset

[@hendrycksmath2021] - Measuring Mathematical Problem Solving with the MATH dataset
[GitHub](https://github.com/hendrycks/math)

- math problems in 7 subjects and 5 difficulty levels
	- probably useful to have difficulty levels?
	- from math contests
- format: latex...
- evaluated using GPT-2/3: low accuracy :c

```json:example
{
    "problem": "A positive multiple of 45 less than 1000 is randomly selected. What is the probability that it is a two-digit integer? Express your answer as a common fraction.",
    "level": "Level 2",
    "type": "Number Theory",
    "solution": "The positive multiples of 45 are  \\[45,90,135,\\ldots,990=1\\cdot45,2\\cdot45,3\\cdot45,\\ldots,22\\cdot45.\\] There are 22 multiples on this list. Every positive multiple of 45 less than 1000 is either a two-digit integer or a three-digit integer. Out of the $99-10+1=90$ two-digit integers, $45$ and $90$ are multiples of 45. Therefore, the probability that the selected multiple of 45 has two digits is $2/22=\\boxed{\\frac{1}{11}}$."
}
```
##### AMPS

pretraining dataset of more basic problems presented in the same paper: **Auxiliary Mathematics Problems and Solutions dataset**
- also set in latex
- 23GB
- Khan Academy and problems generated with Mathematica scripts

### 2. GSM8K dataset

[@cobbe2021gsm8k] - Training Verifiers to Solve Math Word Problems
[GitHub](https://github.com/openai/grade-school-math)

- 8.5k grade school math questions + natural language solutions
- basic arithmetic -> more language-dependent, so good? at least to start simple

```json:example
{
	"question": "Janet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?", 
	"answer": "Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer\u2019s market.\n#### 18"
}
```
##### Modified version

modified version: uses *Socratic subquestions* before each step. basically: give structure to reasoning
- makes reasoning steps more explicit

```json:example
{
	"question": "Janet\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?", 
	"answer": "How many eggs does Janet sell? ** Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\nHow much does Janet make at the farmers' market? ** She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer\u2019s market.\n#### 18"}

```

### 3. AQuA-RAT

[@ling2017aquarat] - Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems
[PapersWithCode](https://paperswithcode.com/paper/program-induction-by-rationale-generation)
[Git](https://github.com/google-deepmind/AQuA)

- 100k problems
- format: question, options, rationale, option
- *rationale*: formalized natural language into "math language" with a seq2seq model

```json:example
{
"question": "A grocery sells a bag of ice for $1.25, and makes 20% profit. If it sells 500 bags of ice, how much total profit does it make?",
"options": ["A)125", "B)150", "C)225", "D)250", "E)275"],
"rationale": "Profit per bag = 1.25 * 0.20 = 0.25\nTotal profit = 500 * 0.25 = 125\nAnswer is A.",
"correct": "A"
}
```

### 4. MathQuest

- problems from high school mathematics NCERT books
- 14 mathematical domains, 223 samples

![[Pasted image 20240515150419.png|MathQuest sample|400]]

- augmented version of math-401 dataset used for fine-tuning

 ---

# STEM ðŸ“ˆ

### 1. TheoremQA

[@chen2023theoremqa] - TheoremQA: A Theorem-driven Question Answering dataset
[Git](https://github.com/TIGER-AI-Lab/TheoremQA)
[Huggingface](https://huggingface.co/datasets/TIGER-Lab/TheoremQA)

- multiple domains: math, electrical engineering, computer science, physics, finance
- 800 QA pairs -> small but high quality?
- also has multimodal

![[Pasted image 20240515141153.png|topics covered in dataset|500]]

![[Pasted image 20240515162456.png|350]]
### 2. SciBench

[@Wang2023SciBenchEC] - SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models
[GitHub](https://github.com/mandyyyyii/scibench)

>examine the reasoning capabilities required for solving complex (*= college level*) scientific problems

1. open set: collegiate-level
2. closed set: undergraduate-level exams

- from textbooks in college-level chemisty, physics, math
- desiderata: college-level, **detailed solutions**, inaccessible in text formats (?), more complex than basic arithmetic

```json:example
{
  "problem_text": "An insurance company sells several types of insurance policies, including auto policies and homeowner policies. Let $A_1$ be those people with an auto policy only, $A_2$ those people with a homeowner policy only, and $A_3$ those people with both an auto and homeowner policy (but no other policies). For a person randomly selected from the company's policy holders, suppose that $P\\left(A_1\\right)=0.3, P\\left(A_2\\right)=0.2$, and $P\\left(A_3\\right)=0.2$. Further, let $B$ be the event that the person will renew at least one of these policies. Say from past experience that we assign the conditional probabilities $P\\left(B \\mid A_1\\right)=0.6, P\\left(B \\mid A_2\\right)=0.7$, and $P\\left(B \\mid A_3\\right)=0.8$. Given that the person selected at random has an auto or homeowner policy, what is the conditional probability that the person will renew at least one of those policies?",
  "answer_latex": " 0.686",
  "answer_number": "0.686",
  "unit": " ",
  "source": "stat",
  "problemid": "Example 1.3.11 ",
  "comment": " ",
  "solution": "The desired probability is\r\n$$\r\n\\begin{aligned}\r\nP\\left(B \\mid A_1 \\cup A_2 \\cup A_3\\right) & =\\frac{P\\left(A_1 \\cap B\\right)+P\\left(A_2 \\cap B\\right)+P\\left(A_3 \\cap B\\right)}{P\\left(A_1\\right)+P\\left(A_2\\right)+P\\left(A_3\\right)} \\\\\r\n& =\\frac{(0.3)(0.6)+(0.2)(0.7)+(0.2)(0.8)}{0.3+0.2+0.2} \\\\\r\n& =\\frac{0.48}{0.70}=0.686 .\r\n\\end{aligned}\r\n$$"
 }
```

-> very LaTeX heavy

---
# Biomedical ðŸ¦ 

### 1. BioNLI

[@bastan-etal-2022-bionli] - BioNLI: Generating a Biomedical NLI Dataset Using Lexico-semantic Constraints for Adversarial Examples
[PapersWithCode](https://paperswithcode.com/dataset/bionli)

- consistent and adversarial hypotheses -> can hypothesis be entailed from premise or not?
	- rule-based and neural-based counterfactuals
- based on [@bastan-etal-2022-sume], a dataset of biomedical abstracts
	- summarization, but also conclusion generation
- pubmedBERT, biolinkBERT
##### SuMe
[Website](https://stonybrooknlp.github.io/SuMe/)

![[Pasted image 20240515160437.png|400]]

### 2. PubMedQA

[@jin2019pubmedqa] - PubMedQA: A Dataset for Biomedical Research Question Answering
[Website](https://pubmedqa.github.io/)
[Git](https://github.com/pubmedqa/pubmedqa)

- articles with questions as titles + abstract w/o conclusive part + conclusive part
	- 1 annotator saw long answer, 1 annotator did not

```json:example
{
        "QUESTION": "Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?",
        "CONTEXTS": [
            "Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants.",
            "The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (\u0394\u03a8m). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells."
        ],
        "LABELS": [
            "BACKGROUND",
            "RESULTS"
        ],
        "MESHES": [
            "Alismataceae",
            "Apoptosis",
            "Cell Differentiation",
            "Mitochondria",
            "Plant Leaves"
        ],
        "YEAR": "2011",
        "reasoning_required_pred": "yes",
        "reasoning_free_pred": "yes",
        "final_decision": "yes",
        "LONG_ANSWER": "Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant."
}
```


---

# Finance ðŸ’µ

### 1. FinQA

[@chen2021finqa] - FinQA: A Dataset of Numerical Reasoning over Financial Data
[Git](https://github.com/czyssrs/FinQA)

![[Pasted image 20240515155921.png]]

- 8k samples
- again, only basic math :c

----
# Logic/Arguments ðŸ§ 

| Advantages          | Disadvantages       |
| ------------------- | ------------------- |
| more language-based | domain-specific...? |

[General](https://paperswithcode.com/task/logical-reasoning)
### 1. Logic / LogicClimate

[@jin-etal-2022-logical] - Logical Fallacy Detection
[Git](https://github.com/causalNLP/logical-fallacy)

- general data: crawled from quiz websites + manual, 2.5k, 13 fallacy types
- climate: from news articles, 1k
- main task: NLI-based classification. introduced structure-awareness.

![[Pasted image 20240515152227.png|400]]

### 2. LFUD

[@li2024reason] - LFUD: Logical Fallacy Understanding Dataset
[Git](https://github.com/YandaGo/LFUD/blob/main/LFUD.csv) 




------------------------------------------------------------------

# Misc/Less interesting

### Math401

[@yuan2023math401] - How well do LLMs perform in Arithmetic tasks? 
[GitHub](https://github.com/GanjinZero/math401-llm)

- 401 constructed arithmetic expressions

### OpenWebMath

[@anand2024mathify] - Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks

- open source

>we define a mathematical document as a document containing either core mathematical contents such as theorems, definitions, proofs, questions and answers, formal mathematics, or interdisciplinary documents featuring mathematical formulas within fields like physics, chemistry, biology, economics, and finance

### ProofPile

[@azerbayev2023proofnet]
[Huggingface](https://huggingface.co/datasets/hoskinson-center/proof-pile)
[GitHub](https://github.com/zhangir-azerbayev/proof-pile)
### LogiQA

[@liu2020logiqa] - LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning
[GitHub](https://github.com/lgw863/LogiQA-dataset)

- logical comprehension problems: 13k paragraph-question-choice triples
- original: chinese, human-translated

![[Pasted image 20240515154821.png]]

-> easy counterfactuals? (combine with wrong answers)
### CASA

[@liu2024casa] - CASA: Causality-driven Argument Sufficiency Assessment
[PapersWithCode](https://paperswithcode.com/paper/casa-causality-driven-argument-sufficiency)
[GitHub](https://github.com/xxxiaol/casa)

### Mindgames

[@sileo2023mindgames] - MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic
[GitHub](https://github.com/sileod/llm-theory-of-mind)

- seems to be very challenging

### Mafia

[@ibraheem2022mafia]
[GitHub](https://github.com/omonida/mafia-dataset)

- dialogue data

### ReClor

[@yu2020reclor] - ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning
### BigBench

[@srivastava2023beyond] - Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models (Google)
[GitHub](https://github.com/google/BIG-bench)
[PapersWithCode](https://paperswithcode.com/dataset/big-bench)

- 204 [tasks](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/keywords_to_tasks.md#summary-table)
### XCOPA

[@ponti2020xcopa] - XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning


----

# Some more causality

[Corr2Cause](https://arxiv.org/pdf/2306.05836)

[Epistemic Phase Transitions in math proofs](https://arxiv.org/pdf/2004.00055v2)

https://paperswithcode.com/task/causal-identification

[CausalCite](https://arxiv.org/pdf/2311.02790)
