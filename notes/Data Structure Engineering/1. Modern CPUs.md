-> hardware has become increasingly complex

>[!goal] goal: develop a reasonably accurate (mental) model

----
# Simple CPU Model

- clock rate: clock cycles per second, in each multiple instructions can be started
- *pipelining*: instructions go through stages -> parallelism
- *execution units*: multiple, heterogeneous (can do different things)
- instructions can occupy on or multiple (many) cycles depending on their complexity
## Speculation

- attempt: extract implicit parallelism (independent instructions, reordering)
- hurdles: data dependencies, control flow dependencies

**speculation**: predict jump destination and start executing that path -> control flow execution
- unsurprisingly that's what the branch predictor is for
- mostly works well (NN level algos), except: **branch mispredictions**, which requires pipeline flush
- in a way also prefetching

----
# Skylake Server

![[Pasted image 20240419234200.png]]
### Caches and Memory

- data structures rarely computation bound (register access/write neglible)
- cache line size: 64byte (fixed-sized blocks)
- [TLB](https://en.wikipedia.org/wiki/Translation_lookaside_buffer) (translation lookaside buffer): 1536 entries

*note: write buffer is per-core, not cache coherent*
##### Comparison of caches

![[Pasted image 20240419233354.png]]

- size per core and latency increase, while bandwidths decrease
- L3 is shared with other cores
##### Testing Data Access Latency

![[Pasted image 20240419233911.png]]

- smooth curve bc of associativity and other caches
- far right side: translating [page tables](https://en.wikipedia.org/wiki/Page_table) increases latency, especially when cache misses start nesting (TLB is cached too)

----
# CPU Counters

- hardware performance counters: instructions, cache/TLB hits/misses, branch hits/misses
- max 4 simultaneously
- can help us understand what is going on in the hardware
- or be used as sanity check/debug (eg instr counter)

*note: numbers are usually normalized by operation, aka: 10M ops taking time X -> use X/10M*

## Example: B-Tree vs Red Black Tree

- 10M 8B key/value pairs
- both $\mathcal{O}(log\> n)$
- both 24 comparisons on average

>[!star] "see what's going on"

![[Pasted image 20240419232945.png]]

observations:
- implementations reasonable: instruction counter / number of comparisons = handful of instructions per comparison
- branch misses: binary trees, 50% wrong (optimized in B-tree)
- cache misses: fewer in B-tree bc of better locality -> ultimately faster
- **instructions per cycle** (IPC): "how well does the code utilize the CPU"

*note: this is with random access. if numbers in order: cache misses mostly gone, RBtree probably better*