// ============================================ NLP LAB ============================================================================

@article{feder2021causalm,
    author = {Feder, Amir and Oved, Nadav and Shalit, Uri and Reichart, Roi},
    title = "{CausaLM: Causal Model Explanation Through Counterfactual Language Models}",
    journal = {Computational Linguistics},
    volume = {47},
    number = {2},
    pages = {333-386},
    year = {2021},
    month = {07},
    issn = {0891-2017},
    doi = {10.1162/coli_a_00404},
    url = {https://doi.org/10.1162/coli\_a\_00404},
    eprint = {https://direct.mit.edu/coli/article-pdf/47/2/333/1938107/coli\_a\_00404.pdf},
}

@article{coden2005domain,
    title = {Domain-specific language models and lexicons for tagging},
    journal = {Journal of Biomedical Informatics},
    volume = {38},
    number = {6},
    pages = {422-430},
    year = {2005},
    issn = {1532-0464},
    doi = {https://doi.org/10.1016/j.jbi.2005.02.009},
    url = {https://www.sciencedirect.com/science/article/pii/S1532046405000213},
    author = {Anni R. Coden and Serguei V. Pakhomov and Rie K. Ando and Patrick H. Duffy and Christopher G. Chute},
    keywords = {Clinical report analysis, Part-of-speech tagging accuracy, Domain adaptation, Clinical information systems, Biomedical domain, Corpus linguistics, Statistical part-of-speech tagging, Hidden Markov Model},
}


@InProceedings{tornes2023forgedreceipts,
      author={Torn{\'e}s, Beatriz Mart{\'i}nez and Boros, Emanuela and Doucet, Antoine and Gomez-Kr{\"a}mer, Petra and Ogier, Jean-Marc},
      editor={Fink, Gernot A. and Jain, Rajiv and Kise, Koichi and Zanibbi, Richard},
      title={Detecting Forged Receipts withÂ Domain-Specific Ontology-Based Entities {\&} Relations},
      booktitle={Document Analysis and Recognition - ICDAR 2023},
      year="2023",
      publisher="Springer Nature Switzerland",
      address="Cham",
      pages="184--199",
      abstract="In this paper, we tackle the task of document fraud detection. We consider that this task can be addressed with natural language processing techniques. We treat it as a regression-based approach, by taking advantage of a pre-trained language model in order to represent the textual content, and by enriching the representation with domain-specific ontology-based entities and relations. We emulate an entity-based approach by comparing different types of input: raw text, extracted entities and a triple-based reformulation of the document content. For our experimental setup, we utilize the single freely available dataset of forged receipts, and we provide a deep analysis of our results in regard to the efficiency of our methods. Our findings show interesting correlations between the types of ontology relations (e.g., has{\_}address, amounts{\_}to), types of entities (product, company, etc.) and the performance of a regression-based language model that could help to study the transfer learning from natural language processing (NLP) methods to boost the performance of existing fraud detection systems.",
      isbn="978-3-031-41682-8",
      url={https://doi.org/10.1007/978-3-031-41682-8_12}
}

@misc{xie2023darwin,
      title={DARWIN Series: Domain Specific Large Language Models for Natural Science}, 
      author={Tong Xie and Yuwei Wan and Wei Huang and Zhenyu Yin and Yixuan Liu and Shaozhou Wang and Qingyuan Linghu and Chunyu Kit and Clara Grazian and Wenjie Zhang and Imran Razzak and Bram Hoex},
      year={2023},
      eprint={2308.13565},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{song2023matscinlp,
      title={MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling}, 
      author={Yu Song and Santiago Miret and Bang Liu},
      year={2023},
      eprint={2305.08264},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2024largecausal,
      title={Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey}, 
      author={Xiaoyu Liu and Paiheng Xu and Junda Wu and Jiaxin Yuan and Yifan Yang and Yuhang Zhou and Fuxiao Liu and Tianrui Guan and Haoliang Wang and Tong Yu and Julian McAuley and Wei Ai and Furong Huang},
      year={2024},
      eprint={2403.09606},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ali2023causalityextraction,
      title = {Causality extraction: A comprehensive survey and new perspective},
      journal = {Journal of King Saud University - Computer and Information Sciences},
      volume = {35},
      number = {7},
      pages = {101593},
      year = {2023},
      issn = {1319-1578},
      doi = {https://doi.org/10.1016/j.jksuci.2023.101593},
      url = {https://www.sciencedirect.com/science/article/pii/S1319157823001477},
      author = {Wajid Ali and Wanli Zuo and Wang Ying and Rahman Ali and Gohar Rahman and Inam Ullah},
      keywords = {Causality classification, Causal relationship, Causality mining, Causal knowledge, Computational linguistics, Causality extraction, Causality Survey},
      abstract = {Researchers in natural language processing are paying more attention to causality mining. Numerous applications of the growing need for efficient and accurate causality mining include question answering, future events predication, discourse comprehension, decision making, scenario generation, medical text mining, and textual entailment. Although causality has long been in the spotlight, but there are still issues that need to be addressed. This study provides a comprehensive review of casualty mining for various application domains available in the new-age literature from 1989 to 2022. We searched and rigorously examined numerous papers in the most reliable libraries for the review, and the terminologies that drive the context are described. Each paper underwent a thorough review process to extract the following meta-data: techniques, target domains, datasets, features, and limits of each approach. This meta-data will aid researchers in selecting the strategy that is most suited to their research needs. The literature is divided into three groups based on critical reviews including traditional, machine learning-based, and deep learning-based approaches. A concise taxonomy that can substantially help new scholars comprehend the field is developed. In order to make it simple for new researchers to start their research, various perspectives and suggestions are offered.}
}

@inproceedings{jin2023cladder,
      title={{CL}adder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models},
      author={Zhijing Jin and Yuen Chen and Felix Leeb and Luigi Gresele and Ojasv Kamal and Zhiheng LYU and Kevin Blin and Fernando Gonzalez Adauto and Max Kleiman-Weiner and Mrinmaya Sachan and Bernhard Sch{\"o}lkopf},
      booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
      year={2023},
      url={https://openreview.net/forum?id=e2wtjx0Yqu}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021},
  url={https://arxiv.org/pdf/2103.03874}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021},
  url={https://arxiv.org/pdf/2110.14168v2}
}

@inproceedings{chen2023theoremqa,
  title={Theoremqa: A theorem-driven question answering dataset},
  author={Chen, Wenhu and Yin, Ming and Ku, Max and Lu, Pan and Wan, Yixin and Ma, Xueguang and Xu, Jianyu and Wang, Xinyi and Xia, Tony},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://arxiv.org/pdf/2305.12524}
}

@inproceedings{ling2017aquarat,
    title = {Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems},
    author = {Ling, Wang and Yogatama, Dani  and Dyer, Chris  and Blunsom, Phil},
    booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics {(Volume 1: Long Papers)}},
    year = {2017},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/P17-1015.pdf},
    pages = {158--167}
}

@inproceedings{bastan-etal-2022-bionli,
    title = "{B}io{NLI}: Generating a Biomedical {NLI} Dataset Using Lexico-semantic Constraints for Adversarial Examples",
    author = "Bastan, Mohaddeseh  and
      Surdeanu, Mihai  and
      Balasubramanian, Niranjan",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.374",
    pages = "5093--5104",
    
}

@inproceedings{bastan-etal-2022-sume,
    title = "{S}u{M}e: A Dataset Towards Summarizing Biomedical Mechanisms",
    author = "Bastan, Mohaddeseh  and
      Shankar, Nishant  and
      Surdeanu, Mihai  and
      Balasubramanian, Niranjan",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.748",
    pages = "6922--6931",
    abstract = "Can language models read biomedical texts and explain the biomedical mechanisms discussed? In this work we introduce a biomedical mechanism summarization task. Biomedical studies often investigate the mechanisms behind how one entity (e.g., a protein or a chemical) affects another in a biological context. The abstracts of these publications often include a focused set of sentences that present relevant supporting statements regarding such relationships, associated experimental evidence, and a concluding sentence that summarizes the mechanism underlying the relationship. We leverage this structure and create a summarization task, where the input is a collection of sentences and the main entities in an abstract, and the output includes the relationship and a sentence that summarizes the mechanism. Using a small amount of manually labeled mechanism sentences, we train a mechanism sentence classifier to filter a large biomedical abstract collection and create a summarization dataset with 22k instances. We also introduce conclusion sentence generation as a pretraining task with 611k instances. We benchmark the performance of large bio-domain language models. We find that while the pretraining task help improves performance, the best model produces acceptable mechanism outputs in only 32{\%} of the instances, which shows the task presents significant challenges in biomedical language understanding and summarization.",
}

@article{sileo2023mindgames,
  title={MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic},
  author={Sileo, Damien and Lernould, Antoine},
  journal={arXiv preprint arXiv:2305.03353},
  year={2023},
  url={https://arxiv.org/pdf/2305.03353v2}
}

@inproceedings{jin-etal-2022-logical,
    title = "Logical Fallacy Detection",
    author = "Jin, Zhijing  and
      Lalwani, Abhinav  and
      Vaidhya, Tejas  and
      Shen, Xiaoyu  and
      Ding, Yiwen  and
      Lyu, Zhiheng  and
      Sachan, Mrinmaya  and
      Mihalcea, Rada  and
      Schoelkopf, Bernhard",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.532.pdf",
    pages = "7180--7198",
    abstract = "Reasoning is central to human intelligence. However, fallacious arguments are common, and some exacerbate problems such as spreading misinformation about climate change. In this paper, we propose the task of logical fallacy detection, and provide a new dataset (Logic) of logical fallacies generally found in text, together with an additional challenge set for detecting logical fallacies in climate change claims (LogicClimate). Detecting logical fallacies is a hard problem as the model must understand the underlying logical structure of the argument. We find that existing pretrained large language models perform poorly on this task. In contrast, we show that a simple structure-aware classifier outperforms the best language model by 5.46{\%} F1 scores on Logic and 4.51{\%} on LogicClimate. We encourage future work to explore this task since (a) it can serve as a new reasoning challenge for language models, and (b) it can have potential applications in tackling the spread of misinformation. Our dataset and code are available at \url{https://github.com/causalNLP/logical-fallacy}",
}

@article{liu2024casa,
  title={CASA: Causality-driven Argument Sufficiency Assessment},
  author={Liu, Xiao and Feng, Yansong and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2401.05249},
  year={2024}
}

@misc{azerbayev2023proofnet,
      title={ProofNet: Autoformalizing and Formally Proving Undergraduate-Level Mathematics}, 
      author={Zhangir Azerbayev and Bartosz Piotrowski and Hailey Schoelkopf and Edward W. Ayers and Dragomir Radev and Jeremy Avigad},
      year={2023},
      eprint={2302.12433},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{anand2024mathify,
      title={Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks}, 
      author={Avinash Anand and Mohit Gupta and Kritarth Prasad and Navya Singla and Sanjana Sanjeev and Jatin Kumar and Adarsh Raj Shivam and Rajiv Ratn Shah},
      year={2024},
      eprint={2404.13099},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yuan2023math401,
      title={How well do Large Language Models perform in Arithmetic tasks?}, 
      author={Zheng Yuan and Hongyi Yuan and Chuanqi Tan and Wei Wang and Songfang Huang},
      year={2023},
      eprint={2304.02015},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Wang2023SciBenchEC,
  title={SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models},
  author={Xiaoxuan Wang and Ziniu Hu and Pan Lu and Yanqiao Zhu and Jieyu Zhang and Satyen Subramaniam and Arjun R. Loomba and Shichang Zhang and Yizhou Sun and Wei Wang},
  journal={arXiv preprint 2307.10635},
  year={2023},
  url={https://mathai2023.github.io/papers/44.pdf}
}

@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={BIG-bench authors},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=uyTL5Bvosj},
  note={}
}

@inproceedings{ibraheem2022mafia,
    title = "Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia",
    author = "Ibraheem, Samee  and
      Zhou, Gaoyue  and
      DeNero, John",
    editor = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.11",
    doi = "10.18653/v1/2022.naacl-main.11",
    pages = "158--168",
    abstract = "While neural networks demonstrate a remarkable ability to model linguistic content, capturing contextual information related to a speaker{'}s conversational role is an open area of research. In this work, we analyze the effect of speaker role on language use through the game of Mafia, in which participants are assigned either an honest or a deceptive role. In addition to building a framework to collect a dataset of Mafia game records, we demonstrate that there are differences in the language produced by players with different roles. We confirm that classification models are able to rank deceptive players as more suspicious than honest ones based only on their use of language. Furthermore, we show that training models on two auxiliary tasks outperforms a standard BERT-based text classification approach. We also present methods for using our trained models to identify features that distinguish between player roles, which could be used to assist players during the Mafia game.",
}

@misc{liu2020logiqa,
      title={LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning}, 
      author={Jian Liu and Leyang Cui and Hanmeng Liu and Dandan Huang and Yile Wang and Yue Zhang},
      year={2020},
      eprint={2007.08124},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yu2020reclor,
      title={ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning}, 
      author={Weihao Yu and Zihang Jiang and Yanfei Dong and Jiashi Feng},
      year={2020},
      eprint={2002.04326},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ponti2020xcopa,
      title={XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning}, 
      author={Edoardo Maria Ponti and Goran GlavaÅ¡ and Olga Majewska and Qianchu Liu and Ivan VuliÄ and Anna Korhonen},
      year={2020},
      eprint={2005.00333},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chen2021finqa,
  title={FinQA: A Dataset of Numerical Reasoning over Financial Data},
  author={Chen, Zhiyu and Chen, Wenhu and Smiley, Charese and Shah, Sameena and Borova, Iana and Langdon, Dylan and Moussa, Reema and Beane, Matt and Huang, Ting-Hao and Routledge, Bryan and Wang, William Yang},
  journal={Proceedings of EMNLP 2021},
  year={2021}
}

@misc{jin2019pubmedqa,
      title={PubMedQA: A Dataset for Biomedical Research Question Answering}, 
      author={Qiao Jin and Bhuwan Dhingra and Zhengping Liu and William W. Cohen and Xinghua Lu},
      year={2019},
      eprint={1909.06146},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2024reason,
      title={Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning through Logical Fallacy Understanding}, 
      author={Yanda Li and Dixuan Wang and Jiaqing Liang and Guochao Jiang and Qianyu He and Yanghua Xiao and Deqing Yang},
      year={2024},
      eprint={2404.04293},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{yang2022surveycer,
  title={A survey on extraction of causal relations from natural language text},
  author={Yang, Jie and Han, Soyeon Caren and Poon, Josiah},
  journal={Knowledge and Information Systems},
  volume={64},
  number={5},
  pages={1161--1186},
  year={2022},
  publisher={Springer}
}

@inproceedings{girju-etal-2007-semeval,
    title = "{S}em{E}val-2007 Task 04: Classification of Semantic Relations between Nominals",
    author = "Girju, Roxana  and
      Nakov, Preslav  and
      Nastase, Vivi  and
      Szpakowicz, Stan  and
      Turney, Peter  and
      Yuret, Deniz",
    editor = "Agirre, Eneko  and
      M{\`a}rquez, Llu{\'\i}s  and
      Wicentowski, Richard",
    booktitle = "Proceedings of the Fourth International Workshop on Semantic Evaluations ({S}em{E}val-2007)",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S07-1003",
    pages = "13--18",
}

@inproceedings{hendrickx-etal-2010-semeval,
    title = "{S}em{E}val-2010 Task 8: Multi-Way Classification of Semantic Relations between Pairs of Nominals",
    author = "Hendrickx, Iris  and
      Kim, Su Nam  and
      Kozareva, Zornitsa  and
      Nakov, Preslav  and
      {\'O} S{\'e}aghdha, Diarmuid  and
      Pad{\'o}, Sebastian  and
      Pennacchiotti, Marco  and
      Romano, Lorenza  and
      Szpakowicz, Stan",
    editor = "Erk, Katrin  and
      Strapparava, Carlo",
    booktitle = "Proceedings of the 5th International Workshop on Semantic Evaluation",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S10-1006",
    pages = "33--38",
}

@inproceedings{prasad-etal-2008-penn,
    title = "The {P}enn {D}iscourse {T}ree{B}ank 2.0.",
    author = "Prasad, Rashmi  and
      Dinesh, Nikhil  and
      Lee, Alan  and
      Miltsakaki, Eleni  and
      Robaldo, Livio  and
      Joshi, Aravind  and
      Webber, Bonnie",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tapias, Daniel",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}'08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2008/pdf/754_paper.pdf",
    abstract = "We present the second version of the Penn Discourse Treebank, PDTB-2.0, describing its lexically-grounded annotations of discourse relations and their two abstract object arguments over the 1 million word Wall Street Journal corpus. We describe all aspects of the annotation, including (a) the argument structure of discourse relations, (b) the sense annotation of the relations, and (c) the attribution of discourse relations and each of their arguments. We list the differences between PDTB-1.0 and PDTB-2.0. We present representative statistics for several aspects of the annotation in the corpus.",
}

@inproceedings{tan-etal-2023-event-causality,
    title = "Event Causality Identification - Shared Task 3, {CASE} 2023",
    author = {Tan, Fiona Anting  and
      Hettiarachchi, Hansi  and
      H{\"u}rriyeto{\u{g}}lu, Ali  and
      Oostdijk, Nelleke  and
      Uca, Onur  and
      Thapa, Surendrabikram  and
      Liza, Farhana Ferdousi},
    editor = {H{\"u}rriyeto{\u{g}}lu, Ali  and
      Tanev, Hristo  and
      Zavarella, Vanni  and
      Yeniterzi, Reyyan  and
      Y{\"o}r{\"u}k, Erdem  and
      Slavcheva, Milena},
    booktitle = "Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text",
    month = sep,
    year = "2023",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd., Shoumen, Bulgaria",
    url = "https://aclanthology.org/2023.case-1.19",
    pages = "144--150",
    abstract = "The Event Causality Identification Shared Task of CASE 2023 is the second iteration of a shared task centered around the Causal News Corpus. Two subtasks were involved: In Subtask 1, participants were challenged to predict if a sentence contains a causal relation or not. In Subtask 2, participants were challenged to identify the Cause, Effect, and Signal spans given an input causal sentence. For both subtasks, participants uploaded their predictions for a held-out test set, and ranking was done based on binary F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper includes an overview of the work of the ten teams that submitted their results to our competition and the six system description papers that were received. The highest F1 scores achieved for Subtask 1 and 2 were 84.66{\%} and 72.79{\%}, respectively.",
}

@inproceedings{tan-etal-2022-causal,
    title = "The Causal News Corpus: Annotating Causal Relations in Event Sentences from News",
    author = {Tan, Fiona Anting  and
      H{\"u}rriyeto{\u{g}}lu, Ali  and
      Caselli, Tommaso  and
      Oostdijk, Nelleke  and
      Nomoto, Tadashi  and
      Hettiarachchi, Hansi  and
      Ameer, Iqra  and
      Uca, Onur  and
      Liza, Farhana Ferdousi  and
      Hu, Tiancheng},
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.246",
    pages = "2298--2310",
    abstract = "Despite the importance of understanding causality, corpora addressing causal relations are limited. There is a discrepancy between existing annotation guidelines of event causality and conventional causality corpora that focus more on linguistics. Many guidelines restrict themselves to include only explicit relations or clause-based arguments. Therefore, we propose an annotation schema for event causality that addresses these concerns. We annotated 3,559 event sentences from protest event news with labels on whether it contains causal relations or not. Our corpus is known as the Causal News Corpus (CNC). A neural network built upon a state-of-the-art pre-trained language model performed well with 81.20{\%} F1 score on test set, and 83.46{\%} in 5-folds cross-validation. CNC is transferable across two external corpora: CausalTimeBank (CTB) and Penn Discourse Treebank (PDTB). Leveraging each of these external datasets for training, we achieved up to approximately 64{\%} F1 on the CNC test set without additional fine-tuning. CNC also served as an effective training and pre-training dataset for the two external corpora. Lastly, we demonstrate the difficulty of our task to the layman in a crowd-sourced annotation exercise. Our annotated corpus is publicly available, providing a valuable resource for causal text mining researchers.",
}

@misc{he2024zeroshot,
      title={Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning}, 
      author={Zhitao He and Pengfei Cao and Zhuoran Jin and Yubo Chen and Kang Liu and Zhiqiang Zhang and Mengshu Sun and Jun Zhao},
      year={2024},
      eprint={2403.02893},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ZHANG2023111072,
      title = {Prompt-based event relation identification with Constrained Prefix ATTention mechanism},
      journal = {Knowledge-Based Systems},
      volume = {281},
      pages = {111072},
      year = {2023},
      issn = {0950-7051},
      doi = {https://doi.org/10.1016/j.knosys.2023.111072},
      url = {https://www.sciencedirect.com/science/article/pii/S0950705123008225},
      author = {Hang Zhang and Wenjun Ke and Jianwei Zhang and Zhizhao Luo and Hewen Ma and Zhen Luan and Peng Wang},
      keywords = {Event relation identification, Prompt tuning, Pre-trained language model, Template generation, Information extraction},
      abstract = {Event Relation Identification (ERI) aims at mining the inter-event dependencies expressed in event-mentioned sentences. The main challenge of this task lies in recognizing the implicit clue for utterances without context words indicating the relation definitely. When confronting a lack of training samples, mainstream techniques fail to efficiently capture the subtle relations between events because the parameters of neural networks cannot be adequately fitted. Although there is a rising trend of using prompt learning to alleviate such issues, existing methods lack optimization of the prompt and prompts-tuning process. These deficiencies lead to two weaknesses: co-occurrence interference and amphibolous prompting. To this end, this paper proposes a Constrained Prefix ATTention mechanism (CPATT) and incorporates it into the traditional prompt-tuning process. In this fashion, our approach integrates context semantic features into dynamic prompts to mitigate co-occurrence interference. Moreover, CPATT supervises the guide effect of prompts via incorporating mutual exclusivity between categories into the loss function. The experimental results on two widely used datasets demonstrate that our method outperforms all state-of-the-art baselines, including GPT3.5-turbo, in terms of intra- and inter-sentence event relation identification tasks.}
}

@inproceedings{liu2023ppat,
  title     = {PPAT: Progressive Graph Pairwise Attention Network for Event Causality Identification},
  author    = {Liu, Zhenyu and Hu, Baotian and Xu, Zhenran and Zhang, Min},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on
               Artificial Intelligence, {IJCAI-23}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Edith Elkind},
  pages     = {5150--5158},
  year      = {2023},
  month     = {8},
  note      = {Main Track},
  doi       = {10.24963/ijcai.2023/572},
  url       = {https://doi.org/10.24963/ijcai.2023/572},
}

@article{wu2023eventcausalityknowledge, 
      title={Identify Event Causality with Knowledge and Analogy}, 
      volume={37}, 
      url={https://ojs.aaai.org/index.php/AAAI/article/view/26610}, 
      DOI={10.1609/aaai.v37i11.26610}, 
      abstractNote={Event causality identification (ECI) aims to identify the
causal relationship between events, which plays a crucial role
in deep text understanding. Due to the diversity of real-world
causality events and difficulty in obtaining sufficient training
data, existing ECI approaches have poor generalizability and
struggle to identify the relation between seldom seen events.
In this paper, we propose to utilize both external knowledge
and internal analogy to improve ECI. On the one hand, we
utilize a commonsense knowledge graph called ConceptNet
to enrich the description of an event sample and reveal the
commonalities or associations between different events. On
the other hand, we retrieve similar events as analogy exam-
ples and glean useful experiences from such analogous neigh-
bors to better identify the relationship between a new event
pair. By better understanding different events through exter-
nal knowledge and making an analogy with similar events, we
can alleviate the data sparsity issue and improve model gener-
alizability. Extensive evaluations on two benchmark datasets
show that our model outperforms other baseline methods by
around 18% on the F1-value on average}, 
      number={11}, 
      journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
      author={Wu, Sifan and Zhao, Ruihui and Zheng, Yefeng and Pei, Jian and Liu, Bang}, 
      year={2023}, 
      month={Jun.}, 
      pages={13745-13753} 
}

@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{mihuailua2013biocause,
  title={BioCause: Annotating and analysing causality in the biomedical domain},
  author={Mih{\u{a}}il{\u{a}}, Claudiu and Ohta, Tomoko and Pyysalo, Sampo and Ananiadou, Sophia},
  journal={BMC bioinformatics},
  volume={14},
  pages={1--18},
  year={2013},
  publisher={Springer}
}

@inproceedings{al-khatib-etal-2023-new,
    title = "A New Dataset for Causality Identification in Argumentative Texts",
    author = "Al Khatib, Khalid  and
      Voelske, Michael  and
      Le, Anh  and
      Syed, Shahbaz  and
      Potthast, Martin  and
      Stein, Benno",
    editor = "Stoyanchev, Svetlana  and
      Joty, Shafiq  and
      Schlangen, David  and
      Dusek, Ondrej  and
      Kennington, Casey  and
      Alikhani, Malihe",
    booktitle = "Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = sep,
    year = "2023",
    address = "Prague, Czechia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.sigdial-1.31",
    doi = "10.18653/v1/2023.sigdial-1.31",
    pages = "349--354",
    abstract = "Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.",
}

// ==================================================== ADVANCED NLP ==============================================================

@misc{vaswani2023attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{raffel2023exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2023},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{borgeaud2022retro,
      title={Improving language models by retrieving from trillions of tokens}, 
      author={Sebastian Borgeaud and Arthur Mensch and Jordan Hoffmann and Trevor Cai and Eliza Rutherford and Katie Millican and George van den Driessche and Jean-Baptiste Lespiau and Bogdan Damoc and Aidan Clark and Diego de Las Casas and Aurelia Guy and Jacob Menick and Roman Ring and Tom Hennigan and Saffron Huang and Loren Maggiore and Chris Jones and Albin Cassirer and Andy Brock and Michela Paganini and Geoffrey Irving and Oriol Vinyals and Simon Osindero and Karen Simonyan and Jack W. Rae and Erich Elsen and Laurent Sifre},
      year={2022},
      eprint={2112.04426},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{rombach2022highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lin2023text,
      title={Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise}, 
      author={Zhenghao Lin and Yeyun Gong and Yelong Shen and Tong Wu and Zhihao Fan and Chen Lin and Nan Duan and Weizhu Chen},
      year={2023},
      eprint={2212.11685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2022diffusionlm,
      title={Diffusion-LM Improves Controllable Text Generation}, 
      author={Xiang Lisa Li and John Thickstun and Ishaan Gulrajani and Percy Liang and Tatsunori B. Hashimoto},
      year={2022},
      eprint={2205.14217},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kaplan2020scaling,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{reimers2019sentencebert,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{ziwei2024fincausality,

      author={Xu, Ziwei and Takamura, Hiroya and Ichise, Ryutaro},
      booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
      title={A Framework to Construct Financial Causality Knowledge Graph from Text}, 
      year={2024},
      volume={},
      number={},
      pages={57-64},
      keywords={Visualization;Semantics;Cause effect analysis;Knowledge graphs;Transforms;Task analysis;Portfolios;Knowledge representation;Causality;Finance},
      doi={10.1109/ICSC59802.2024.00015}
}


@article{boncz2020fsst,
  title={FSST: fast random access string compression},
  author={Boncz, Peter and Neumann, Thomas and Leis, Viktor},
  journal={Proceedings of the VLDB Endowment},
  volume={13},
  number={12},
  pages={2649--2661},
  year={2020},
  publisher={VLDB Endowment},
  url={https://raw.githubusercontent.com/cwida/fsst/master/fsstcompression.pdf}
}

@article{gaffneyperfect,
  title={Is Perfect Hashing Practical for OLAP Systems?},
  author={Gaffney, Kevin P and Patel, Jignesh M},
  url={https://www.cidrdb.org/cidr2024/papers/p65-gaffney.pdf}
}

@article{barber2014memory,
  title={Memory-efficient hash joins},
  author={Barber, Ronald and Lohman, Guy and Pandis, Ippokratis and Raman, Vijayshankar and Sidle, Richard and Attaluri, Gopi and Chainani, Naresh and Lightstone, Sam and Sharpe, David},
  journal={Proceedings of the VLDB Endowment},
  volume={8},
  number={4},
  pages={353--364},
  year={2014},
  publisher={VLDB Endowment},
  url={http://www.vldb.org/pvldb/vol8/p353-barber.pdf}
}

