- operations: `lookup(key)`, `insert(key, value)`, `remove(key)`
- different requirements depending on application

direct addressing: very fast but very inefficient in terms of space -> small/dense key ranges

##### Hashing

>[!info] hash function $h$ maps from domain $U$ to position in table of size $m$

desiderata:
- fast computation
- small probability of collisions

**collision**: two keys with same hashes -> pigeonhole principle

---
# Chaining

>[!idea] each position has linked list of entries

- most general purpose hash tables
- size of $m$: avg chain length should be constant -> $m \propto n$

**fill factor** $f$:  $m > f \cdot n$
- represents trade-off between time and space
- often close to $1$
### Rehashing

>[!int] if table has to grow dynamically

- create lager table and insert old entries
- chaining: just reuse pointers to old entries
- *exponential growth* desirable
	- constant amortized insertion time
	- again trade-off
	- often factor $g=2$ aka doubling

alternatively: [linear hashing](https://en.wikipedia.org/wiki/Linear_hashing), [extendible hashing](https://en.wikipedia.org/wiki/Extendible_hashing) -> smooth growth, one bucket at a time

---
# Hash Functions

>[!info] should "look random, but be deterministic" and be reasonably fast

- deterministic: no worst-case guarantees

randomized properties: 
1. weakest: collision probability $1/m$ for distinct keys
2. pairwise independence: collision probability $\frac{1}{mÂ²}$
3. $k$-independence: probability of any $k$ distinct keys having some particular hash is $1/m^{k}$
## Modulo prime hashing
$$h(x) = x\> \%\> p$$where $p$ is prime
- $p=m$
- integer keys
- can be attacked by inserting vals with keys that are multiples of $p$

**fast modulo**: integer division is expensive 
- alternative: [multiplicative inverse with magic value](https://databasearchitects.blogspot.com/2020/01/all-hash-table-sizes-you-will-ever-need.html)
## Powers of Two

>[!idea] idea: restrict $m$ to powers of 2

- modulo by bit shift/mask
## Murmur hash

>[!int] "throwing bits around"

mostly cheap operations, as a whole comparable to integer division

```cpp
static uint64_t MurmurHash64A(uint64_t k) {
	const uint64_t m = 0xc6a4a7935bd1e995;
	const int r = 47;
	uint64_t h = 0x8445d61a4e774912 ^ (8*m);
	k *= m;
	k ^= k >> r;
	k *= m;
	h ^= k;
	h *= m;
	h ^= h >> r;
	h *= m;
	h ^= h >> r;
	return h;
}
```

- throughput can be estimated with info about hardware -> lower bound
## Tabulation Hashing

![[notes/Data Structure Engineering/Untitled Diagram 2.svg]]
![[notes/Data Structure Engineering/Untitled Diagram 3.svg]]

- 3-independent, efficient hw implementation
- consumes CPU cache, random state grows with key size

## In practice

- mostly hash functions without guarantees are used
- [empirical evaluation](https://github.com/rurban/smhasher)
- 

---
# Open Addressing

>[!idea] chaining can lead to dependend cache misses -> store data directly

**linear probing**: in case of collision, insert into next free position
- low $f$ required for good performance ($\approx 0.5$)
- deletion becomes more complicated -> tombstones
- lookup must go through entries, esp tombstones

## Performance
32M key/value pairs, 50% fill factor, MurmurHash

![[Pasted image 20240425111640.png|lookup performance for naive benchmark]]

```cpp
for i from 0 to n
	lookup(k[i])
```

-> CPU knows what's next

>[!idea] introduce data dependencies
>- create big cycle thorough entries
>- use value of one lookup as key for the next

![[Pasted image 20240425111347.png|lookup performance for benchmark with data dependencies]]

- more cycles needed
- less cache misses bc less speculation possible in the first place
- number of instructions: checks out, see hash function
- branch misses: come from checking if key is at pos
	- depends on chain length for chaining, *probe sequence length* for open addressing

**probe sequence length**: distance of key from preferred location

![[Pasted image 20240425112145.png|chain length (left) vs probe sequence length (right)|400]]

**clustering effect**: once cluster has started, it tends to grow
- modification: fixed-size groups of entries, typically size of a cache line
- counter needed tho

## Open Addressing and Chaining

>[!info] can also combine open addressing and chaining
>first element in array, then chain
##### Comparison

|                        | Chaining              | Open Addressing                                            |
| ---------------------- | --------------------- | ---------------------------------------------------------- |
| variable-sized entries | yes                   | no                                                         |
| growth                 | growth: random access | growth: iterating through entries is sequential            |
| implementation         | easy                  | hard, especially deletion                                  |
| duplicate keys         |                       | only **kinda** sequential, also other keys may be affected |
| high fill factors      | yay                   | nay                                                        |
| entry copying          | just copy pointers    | must copy the whole thing                                  |

- chaining allows for variable-sized entries
- growth: iterating through old entries is actually sequential for open addressing

----
# Robin Hood Hashing

>[!idea] re-order elements during insertion based on probe sequence length

- esp better than linear for larger fill factors

---
# Cuckoo Hashing
-> constant lookup in worst case

>[!idea] 2 hashtables with diff hash functions

- lookup: check 2 positions
- insert: also check 2 positions
	- if both occupied: rearrange (keep kicking entries out and put them into their alternative spot)
	- if rearrange leads to cycle: completely rebuild w/ different hash function -> very rare!

*NOTE: needs low fill factors. can use more than 2*

>[!info] independent memory accesses -> faster than chaining

---
# Static Hash Tables

>[!goal] no growth -> focus on lookup 
## Static Perfect Hashing

![[Pasted image 20240502102518.png]]
[@gaffneyperfect]

>[!int] hash function becomes a data structure
>aka store seeds per bucket/partition

![[Pasted image 20240502103416.png]]

## FKS Hashing

>[!idea] two-level thingy
>for n elements:
>- $2(n-1)$ partitions: most will be empty or have 1 element 
>- if more: $r$ entries in partition -> build hash table with $r^2$ elements
>	- on collisions: different hash function/re-seed

in theory:
- $\mathcal{O}(1)$ worst case lookup
- $\mathcal{O}(1)$ amortized insert

in practice:
- uses a loooot of space
- dependent cache misses :c
## Concise Hashtable
[@barber2014memory]

>[!idea] open addressing is pretty fast but needs a lot of space (low fill factor) -> compress away free spots

![[Pasted image 20240502103811.png|500]]

bottom right:
- bit map: pattern of slots (first 32bits)
- prefix count: how many bits are set previously (1st row has 3, 2nd has 2) (last 32bits)
#### Lookup

![[Pasted image 20240502104149.png|500]]

- linear probing threshold: if over, put into overflowHT
	- prevents clustering
	- slow but rare access
#### Construction

assumes unique keys, three phases:
1. hash each key and set bit in bitmap with linear probing on collision (above threshold: insert into overflow HT)
2. compute prefix popcounts for bitmap
3. hash each key again and insert into array using prefix popcount

---
# Tips and Tricks

##### Storing Hashes

- avoid recomputing
- needs more space tho

##### Growth

doubling power of two = one more bit
- bit is added either at most or at least significant position
- keep entries together for better cache locality

##### Memory Allocation

- entries either individually (more overhead) or in blocks