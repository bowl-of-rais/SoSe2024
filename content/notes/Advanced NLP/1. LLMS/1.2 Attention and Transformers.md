today: **encoder/decoder-only**
- distinction blurred these days (not too important)
- whats more important: **kind of masking**
- embeddings are also kinda an encoding anyways

---
# Attention

*reminder: sum weighted by similarity scores*

benefits:
- alignment
- multi-head attention. more variants to weigh attention

disadvantages:
- large context desirable, but attention is quadratic
- alternatives: diffusion for text

# Transformer

Paper: [@vaswani2023attention]

![[Pasted image 20240419152435.png]]